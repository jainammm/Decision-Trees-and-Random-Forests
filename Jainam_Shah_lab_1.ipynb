{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    },
    "colab": {
      "name": "Jainam Shah - lab_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7haL3JhQf5Ng",
        "colab_type": "text"
      },
      "source": [
        "### Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_hnGk4WcXg1",
        "colab_type": "code",
        "outputId": "9232876b-2faf-484e-c1ea-2f723e991a97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mAVFCgWksnU",
        "colab_type": "text"
      },
      "source": [
        "### Download Additional Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cv4TtgK3wLaR",
        "colab_type": "code",
        "outputId": "4e8816a8-17d0-449b-9f75-b40155ad0a3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "! python -m nltk.downloader punkt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FdoiEZFcUG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTy0mUcdcUHH",
        "colab_type": "text"
      },
      "source": [
        "#                                               Lab 1 - Weightage - 3%\n",
        "\n",
        "##  Decision Trees and Random Forests\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKPkB_szcUHO",
        "colab_type": "text"
      },
      "source": [
        "### Dataset used : Amazon Fine food reviews.\n",
        "### Maximum points in lab : 75 pts.\n",
        "#### Important points to remember :\n",
        " 1. Observations for the experiments done should be explained.\n",
        " 2. All the code should be submitted in form of single Jupyter notebook itself.\n",
        " 3. Points for each sub-section are mentioned in appropriate question.\n",
        " 4. Make sure to begin early since few experiments may consume more time to run.\n",
        " 5. You can use Google colab to run in jupyter notebook (https://colab.research.google.com/) How to load data in Google Colab ?(https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92)\n",
        " 6. The lab must be submitted on Google classroom. The code as well as the accompanying observations should be made part of the python notebook.\n",
        " 7. __The lab is due on Feb 7th 11.59pm.__\n",
        " 8. __The lab should be completed individually. Students are expected to follow the honor code of the class.__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-m-byfd8cUHR",
        "colab_type": "text"
      },
      "source": [
        "### 1. Go through [scikit learn DecisionTree documentation] : https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
        "### Explain briefly various options available in corresponding DecisionTree classifier in scikit-learn package. [5 pts]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU-Hli7bcUHS",
        "colab_type": "text"
      },
      "source": [
        "# Add your description of the function here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9Vl6_UGcUHW",
        "colab_type": "text"
      },
      "source": [
        "The Amazon Fine Food Reviews dataset consists of reviews of fine foods from Amazon.<br>\n",
        "\n",
        "Number of reviews: 568,454<br>\n",
        "Number of users: 256,059<br>\n",
        "Number of products: 74,258<br>\n",
        "Timespan: Oct 1999 - Oct 2012<br>\n",
        "Number of Attributes/Columns in data: 10 \n",
        "\n",
        "Attribute Information:\n",
        "\n",
        "1. Id\n",
        "2. ProductId - unique identifier for the product\n",
        "3. UserId - unqiue identifier for the user\n",
        "4. ProfileName\n",
        "5. HelpfulnessNumerator - number of users who found the review helpful\n",
        "6. HelpfulnessDenominator - number of users who indicated whether they found the review helpful or not\n",
        "7. Score - rating between 1 and 5 \n",
        "8. Time - timestamp for the review\n",
        "9. Summary - brief summary of the review\n",
        "10. Text - text of the review\n",
        "\n",
        "Out of above attributes we will consider <strong>Score as Y or Output variable</strong>, and  <strong>Summary as X or data points.</strong>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGTlSuW4cUHZ",
        "colab_type": "text"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joAsvLePcUHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from IPython.display import HTML\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "import pickle\n",
        "import sqlite3\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvgIKvhbcUHj",
        "colab_type": "text"
      },
      "source": [
        "### 2.  Dataset loading, train test split, print two data points after converting score column into positive, negative class - [5 pts]\n",
        "#### steps :\n",
        " Use score column as the output variable and Summary as the input variable\n",
        " 1. Convert score column as score > 3 - positive class and score <=3 as negative class.\n",
        " 2. Now define train test split as 0.25."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tQkiE-yXcUHm",
        "colab_type": "code",
        "outputId": "e5d42024-e02f-488b-8aab-8342a8362924",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# connecting to the dataset server to download the amazon fine foods dataset. Do not make any changes to the code below\n",
        "con = sqlite3.connect('/content/gdrive/My Drive/datasets/amazon-fine-food-reviews/database.sqlite')\n",
        "messages = pd.read_sql_query(\"\"\"\n",
        "SELECT Score, Summary\n",
        "FROM Reviews\n",
        "\"\"\", con)\n",
        "\n",
        "# the parition function applied threshold on the rating to label a review as 'positive' or 'negative'.\n",
        "def partition(x):\n",
        "  if x > 3:\n",
        "    return 1\n",
        "  \n",
        "  return 0\n",
        "\n",
        "Score = messages['Score']\n",
        "Score = Score.map(partition)\n",
        "Summary = messages['Summary']\n",
        "\n",
        "# call the function to create the train and test splits according to the ratio 75:25\n",
        "# uncomment and complete the line below\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(Summary, Score, test_size=0.25, random_state=107)\n",
        "\n",
        "# print an example of the dataset after the labeling process\n",
        "print(messages.head(2))\n",
        "tmp = messages\n",
        "tmp['Score'] = tmp['Score'].map(partition)\n",
        "print('\\n', tmp.head(2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Score                Summary\n",
            "0      5  Good Quality Dog Food\n",
            "1      1      Not as Advertised\n",
            "\n",
            "    Score                Summary\n",
            "0      1  Good Quality Dog Food\n",
            "1      0      Not as Advertised\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76EU8SydcUHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# do not change make any changes to the code below. This part of the\n",
        "# code removes stop words and transforms all the words and letters\n",
        "# into a uniform representation. Further, it also removes punctuation\n",
        "# marks.\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def stem_tokens(tokens, stemmer):\n",
        "    stemmed = []\n",
        "    for item in tokens:\n",
        "        stemmed.append(stemmer.stem(item))\n",
        "    return stemmed\n",
        "\n",
        "def tokenize(text):\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    stems = stem_tokens(tokens, stemmer)\n",
        "    return ' '.join(stems)\n",
        "\n",
        "intab = string.punctuation\n",
        "outtab = \"                                \"\n",
        "trantab = str.maketrans(intab, outtab)\n",
        "\n",
        "corpus = []\n",
        "count_train_x=0\n",
        "for text in train_X:\n",
        "    count_train_x=count_train_x+1\n",
        "    text = text.lower()\n",
        "    text = text.translate(trantab)\n",
        "    text=tokenize(text)\n",
        "    corpus.append(text)\n",
        "        \n",
        "count_test_x=0\n",
        "test_set=[]\n",
        "for text in test_X:\n",
        "    count_test_x=count_test_x+1\n",
        "    text = text.lower()\n",
        "    text = text.translate(trantab)\n",
        "    text=tokenize(text)\n",
        "    test_set.append(text)\n",
        "\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(corpus)        \n",
        "X_test_counts = count_vect.transform(test_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1H0MYD5cUH2",
        "colab_type": "text"
      },
      "source": [
        "### 4. Print before and after using data pre-processing for five data points - [5 pts]\n",
        "For example, following are some outputs that we were able to generate\n",
        "\n",
        " ID | Before preprocessing | After preprocessing \n",
        " -|-|-\n",
        " 45612 | Good Strong Flavor|good strong flavor \n",
        " 180139 | GREAT SIDE DISH | great side dish \n",
        " 541273 | Its agar | it agar \n",
        " 102774 | Great product! | great product\n",
        " 447382 | Love them | love them "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnXBqiGxcUH4",
        "colab_type": "code",
        "outputId": "fda7aa21-cc5c-4861-bdb5-e15647a3d848",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "# Data before the processing step is stored in the variable train_X \n",
        "# and the processed data is present in corpus. Print randomly 5 \n",
        "# instances to check the success of the processing step. \n",
        "\n",
        "# Convert train_X to a DataFrame and then append it with corpus.\n",
        "comparedData = train_X.to_frame()\n",
        "comparedData['After Preprocessing'] = corpus\n",
        "comparedData.rename(columns = {'index':'id', 'Summary':'Before Preprocessing'}, inplace=True)\n",
        "\n",
        "# Use sample() to print random instances \n",
        "comparedData.sample(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>before</th>\n",
              "      <th>after</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>426126</th>\n",
              "      <td>I can eat pasta again!</td>\n",
              "      <td>i can eat pasta again</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361373</th>\n",
              "      <td>Texas Toothpicks are wonderful</td>\n",
              "      <td>texa toothpick are wonder</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178241</th>\n",
              "      <td>Distinct Odor but I Really Like It ..</td>\n",
              "      <td>distinct odor but i realli like it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225041</th>\n",
              "      <td>WOW! Smoky With A Nice Slow Burn</td>\n",
              "      <td>wow smoki with a nice slow burn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157153</th>\n",
              "      <td>BEWARE!</td>\n",
              "      <td>bewar</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       before                               after\n",
              "426126                 I can eat pasta again!               i can eat pasta again\n",
              "361373         Texas Toothpicks are wonderful           texa toothpick are wonder\n",
              "178241  Distinct Odor but I Really Like It ..  distinct odor but i realli like it\n",
              "225041       WOW! Smoky With A Nice Slow Burn     wow smoki with a nice slow burn\n",
              "157153                                BEWARE!                               bewar"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Wr_CVpmcUH9",
        "colab_type": "text"
      },
      "source": [
        "### 5. Build a basic decision tree choosing appropriate min_samples_leaf parameter so that tree fits in output cell using Graphviz package [5 pts]\n",
        "Use the decision tree classifier from the sklearn library to learn a decision tree from the training dataet. For now, we would like to only visualize the tree to ensure that we are calling the correct function. Set the min_samples_leaf parameter to a high value (>15000) for learning the tree. This tree will not be accurate, but will be big enough for us to visualize it. Identify the functions in the tree package that will help to visualize the tree and plot it. Below is a sample tree generated when mi_samples_leaf was set to 20000\n",
        "![tree.png](attachment:tree.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZVAsEaocUIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import tree"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZAm4XK1cUIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decisionTree = tree.DecisionTreeClassifier(min_samples_leaf=18000)\n",
        "\n",
        "# Using *train_y.values* because the indexing has been changed in preprocessing\n",
        "decisionTree = decisionTree.fit(X_train_counts, train_y.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mjp_8cvSgRBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "from sklearn.externals.six import StringIO  \n",
        "from IPython.display import Image  \n",
        "import pydotplus\n",
        "\n",
        "dot_data = export_graphviz(decisionTree, out_file=None,  \n",
        "                filled=True, rounded=True,\n",
        "                special_characters=True, class_names=['0','1'])\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "\n",
        "Image(graph.create_png())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYtsEceUcUIL",
        "colab_type": "text"
      },
      "source": [
        "### 6. Experiments with different tree parameters\n",
        "#### a. minimum number of samples in a node.  [5 pts]\n",
        "By now we should have all the code in place for learning accurate decision trees. As we discussed in the class, one method to prevent overfitting a decision tree is to put constraints on the number of samples assigned to a split node during training. We had used this parameter to learn extremely short decision trees in the previous step. Let us now vary this parameter and investigate the impact on the train and test accuracy of the model. \n",
        "The first part of the code should loop around different values for min_samples_split and save the resulting train and test accuracy. In the second part, plot a graph with x-axis being the number of samples in the node and accuracy being the y axis. Plot both the train and test accuracies in the same figure. Write a generic function for the plotting as we will use it later for other visualizations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPcLLgq1cUIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_accuracy_list=[]\n",
        "train_accuracy_list=[]\n",
        "min_samples_split = [10,50,100,200]\n",
        "for i in min_samples_split:\n",
        "  dt = tree.DecisionTreeClassifier(min_samples_split = i, random_state=107)\n",
        "  dt.fit(X_train_counts, train_y.values)\n",
        "\n",
        "  test_accuracy_list.append(dt.score(X_test_counts, test_y.values))\n",
        "  train_accuracy_list.append(dt.score(X_train_counts, train_y.values))\n",
        "\n",
        "    \n",
        "def plot_accuracy(test_accuracy_list,train_accuracy_list, xlabel, ylabel, title):\n",
        "  plt.plot(xaxis, train_accuracy_list, color='g', label=\"Train Accuracy\")\n",
        "  plt.plot(xaxis, test_accuracy_list, color='orange', label=\"Test Accuracy\")\n",
        "  plt.legend()\n",
        "  plt.xlabel(x_label)\n",
        "  plt.ylabel(y_label)\n",
        "  plt.title(graph_title)\n",
        "  plt.show()\n",
        "    \n",
        "    \n",
        "plot_accuracy(min_samples_split, test_accuracy_list,train_accuracy_list, 'min_samples_split', 'Accuracy', 'Minimum Number of Samples in a Node')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eznt-O63cUIV",
        "colab_type": "text"
      },
      "source": [
        "#### b. maximum number of leaf nodes in the tree [5 pts]\n",
        "The tree learner has a parameter max_leaf_nodes. Discuss the role of this parameter during the tree learning. Investigate the impact of this parameter on the train and test accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgPv04_xcUIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_accuracy_list=[]\n",
        "train_accuracy_list=[]\n",
        "xaxis=[]\n",
        "max_leaf_nodes=1000\n",
        "step_size_2=50\n",
        "for i in range(2, max_leaf_nodes,step_size_2):\n",
        "  xaxis.append(i)\n",
        "\n",
        "  dt = tree.DecisionTreeClassifier(max_leaf_nodes = i, random_state=107)\n",
        "  dt.fit(X_train_counts, train_y.values)\n",
        "\n",
        "  test_accuracy_list.append(dt.score(X_test_counts, test_y.values))\n",
        "  train_accuracy_list.append(dt.score(X_train_counts, train_y.values))\n",
        "\n",
        "plot_accuracy(xaxis, test_accuracy_list, train_accuracy_list, 'max_leaf_nodes', 'Accuracy', 'Maximum Number of Leaf Nodes in the Tree')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrFEynB1cUIc",
        "colab_type": "text"
      },
      "source": [
        "#### c. splitting criteria [5 pts]\n",
        "Identify the default splitting critera and experiment with other criterion implemented in the tree package. Report the accuracy on the test dataset as well as other parameters chracterizing the learned decision tree. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TaFcL-vcUIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# insert your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kf5YmQOCcUIk",
        "colab_type": "text"
      },
      "source": [
        "#### d. depth of the decision tree [5 pts]\n",
        "Investigate the impact of depth of the decision tree on the test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOH1tkCZcUIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_accuracy_list=[]\n",
        "train_accuracy_list=[]\n",
        "xaxis=[]\n",
        "maximum_depth=1000\n",
        "step_size=50\n",
        "for i in range(1, maximum_depth,step_size):\n",
        "  xaxis.append(i)\n",
        "\n",
        "  dt = tree.DecisionTreeClassifier(max_depth = i, random_state=107)\n",
        "  dt.fit(X_train_counts, train_y.values)\n",
        "\n",
        "  test_accuracy_list.append(dt.score(X_test_counts, test_y.values))\n",
        "  train_accuracy_list.append(dt.score(X_train_counts, train_y.values))\n",
        "\n",
        "plot_accuracy(xaxis, test_accuracy_list, train_accuracy_list, 'max_depth', 'Accuracy', 'Varying Depth of Decision Tree')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPPQHZM5cUIs",
        "colab_type": "text"
      },
      "source": [
        "### 7. Random forest\n",
        "Now, let us explore an ensemble of decision trees - random forest. Fortunately, sklearn has an ensemble library containing the random forest classifier. Let us learn a random forest using both instance and feature bagging independently.\n",
        "#### a. briefly describe the input parameters to the random forest classifier [5 pts]\n",
        "insert your description here\n",
        "#### b. instance bagging [10 pts]\n",
        "As discussed in the class, instances are sampled with replacement to create multiple synthetic training sets. Decision tree is learned for every training set. An ensemble strategy (majority voting) is applied on the output of all the trees for a test instance. Let us vary the number of instances in each bag to learn the random forest and check if there is impact on the performance of the ensemble. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74B4Ob8PcUIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import random\n",
        "test_accuracy_list=[]\n",
        "train_accuracy_list=[]\n",
        "number_of_instances = [1000,5000,10000,20000]\n",
        "for i in number_of_instances:\n",
        "    # insert your code here\n",
        "\n",
        "plot_accuracy(test_accuracy_list, train_accuracy_list, xlabel, ylabel, title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_EgPxVmcUI0",
        "colab_type": "text"
      },
      "source": [
        "#### c. feature bagging [10 pts]\n",
        "For performing feature bagging, we sample a subset of features from the initial set of features. A decision tree is learned for every training set that contains all the instances characterized by a subset of features. An ensemble strategy is applied for classifying a test instance. In this experiment we will investigate the impact of varying the number of features bagged on the test accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azArpfQKcUI2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_accuracy_list=[]\n",
        "train_accuracy_list=[]\n",
        "number_of_features = [1000,10000,15000,20000]\n",
        "for i in number_of_features:\n",
        "    # insert your code here\n",
        "\n",
        "    \n",
        "plot_accuracy(test_accuracy_list ,train_accuracy_list, xlabel, ylabel, title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hojQaKNvcUI6",
        "colab_type": "text"
      },
      "source": [
        "#### d. number of trees in the forest [10 pts]\n",
        "Finally let us vary the number of trees in the random forest. We will use the default random forest classifier and only vary the number of trees learned in the ensemble. Again make your observations on the test accuracy as the number of trees are varied."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "rtuTHxSfcUI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_accuracy_list=[]\n",
        "train_accuracy_list=[]\n",
        "number_of_trees = [1,2,5,10,50]\n",
        "for i in number_of_trees:\n",
        "    # insert your code here\n",
        "    \n",
        "plot_accuracy(test_accuracy_list ,train_accuracy_list, xlabel, ylabel, title)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}